{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "Jx1OkfHoEfun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV_G6bOVB4xA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "QOtEqohQEkw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_batchsize=50000\n",
        "test_batchsize=10000\n",
        "Net_layers = [784,500,500,500]\n",
        "threshold = 3.0\n",
        "learning_rate = 0.03\n",
        "epochs = 1000\n"
      ],
      "metadata": {
        "id": "4MrKpX5RFCmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "A1EqlTKDFE01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_loader():\n",
        "\n",
        "    # Calculate the mean and standard deviation of the MNIST training dataset\n",
        "    train_dataset = MNIST('./data/', train=True, download=True, transform=ToTensor())\n",
        "    train_mean = train_dataset.data.float().mean() / 255.0\n",
        "    train_std = train_dataset.data.float().std() / 255.0\n",
        "\n",
        "    # Define the Z-score normalization transformation\n",
        "    transform = Compose([ToTensor(), Normalize(mean=(train_mean,), std=(train_std,)), Lambda(lambda x: x.view(-1))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MNIST('./data/', train=True, download=True, transform=transform),\n",
        "        batch_size=train_batchsize, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        MNIST('./data/', train=False, download=True, transform=transform),\n",
        "        batch_size=test_batchsize, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "0-VMf3ttFEbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate data"
      ],
      "metadata": {
        "id": "Z93aSjf1OAjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def y_OneHot_on_x(x, y):\n",
        "    \"\"\"Replace the first 10 pixels of data [x] with one-hot-encoded label [y]\n",
        "    \"\"\"\n",
        "    x_ = x.clone()\n",
        "    x_[:, :10] *= 0.0\n",
        "    x_[range(x.shape[0]), y] = x.max()\n",
        "\n",
        "    return x_"
      ],
      "metadata": {
        "id": "u7SXx5pqN26Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_y_neg(y):\n",
        "    # Generate a random tensor of labels\n",
        "    y_neg = torch.randint(0, 10, size=y.size(), device=y.device)\n",
        "\n",
        "    # Find the positions where the random labels match the original labels\n",
        "    match_positions = (y_neg == y)\n",
        "\n",
        "    # Replace these positions with another random choice\n",
        "    while match_positions.any():\n",
        "        y_neg[match_positions] = torch.randint(0, 10, size=(match_positions.sum().item(),), device=y.device)\n",
        "        match_positions = (y_neg == y)\n",
        "\n",
        "    return y_neg"
      ],
      "metadata": {
        "id": "J7KpatOHlIeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define NetWork"
      ],
      "metadata": {
        "id": "o1SiooSBg3FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetWork(torch.nn.Module):\n",
        "    def __init__(self, dims):\n",
        "        super().__init__()\n",
        "        # Initialize layers of the network based on the provided dimensions\n",
        "        self.layers = [Layer(dims[d], dims[d + 1]).cuda() for d in range(len(dims) - 1)]\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Initialize list to store goodness of each label\n",
        "        g_for_labels = []\n",
        "        # Iterate over each label\n",
        "        for label in range(10):\n",
        "            h = y_OneHot_on_x(x, label)\n",
        "            goodness = []\n",
        "            # Pass the input through each layer and calculate goodness\n",
        "            for layer in self.layers:\n",
        "                h = layer(h)\n",
        "                goodness += [h.pow(2).mean(1)]\n",
        "            # Sum the goodness of all layers for the current label\n",
        "            g_for_labels += [sum(goodness)]\n",
        "\n",
        "        # Return the label with the maximum goodness\n",
        "        return  torch.stack(g_for_labels, dim=1).argmax(dim=1)\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        # Initialize positive and negative inputs\n",
        "        h_pos, h_neg = x_pos, x_neg\n",
        "        # Train each layer\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print('training layer', i+1, '...')\n",
        "            h_pos, h_neg = layer.train(h_pos, h_neg)\n"
      ],
      "metadata": {
        "id": "SXE2vqHVLAck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "goodness function is defined as:\n",
        "$$\n",
        "g = \\frac{1}{M} \\sum_{j=1}^{M} y_j^2\n",
        "$$\n"
      ],
      "metadata": {
        "id": "xkHWntky9GHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function is defined as:\n",
        "\n",
        "$$\n",
        "\\text{loss} = \\frac{1}{N} \\sum_{i=1}^{N} \\log\\left(1 + \\exp\\left(\\text{torch.cat}\\left([\\text{threshold} - g_{\\text{pos},i} , g_{\\text{neg},i} - \\text{threshold}]\\right)\\right)\\right)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "9_d4rz4E-jv0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30JVLce_B4xC"
      },
      "outputs": [],
      "source": [
        "class Layer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.opt = Adam(self.parameters(), lr=learning_rate)\n",
        "        self.th = threshold\n",
        "        self.num_epochs = epochs\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Normalize the input tensor along the second dimension\n",
        "        x.div_(x.norm(2, 1, keepdim=True) + 1e-4)\n",
        "\n",
        "        # Perform a linear transformation\n",
        "        out = (x.mm(self.weight.T)+self.bias.unsqueeze(0))\n",
        "\n",
        "        # Apply the ReLU activation function\n",
        "        return out.relu()\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "      # Iterate over the number of epochs\n",
        "      for i in tqdm(range(self.num_epochs)):\n",
        "          # Forward pass for positive and negative samples, calculate the Goodness fuction\n",
        "          g_pos = self.forward(x_pos).pow(2).mean(1)\n",
        "          g_neg = self.forward(x_neg).pow(2).mean(1)\n",
        "\n",
        "          # Calculate the loss\n",
        "          loss = torch.mean(torch.log(1 + torch.exp(torch.cat([self.th - g_pos , g_neg - self.th]))))\n",
        "\n",
        "          # Zero the gradients before running the backward pass\n",
        "          self.opt.zero_grad()\n",
        "\n",
        "          # Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
        "          loss.backward()\n",
        "\n",
        "          # Calling the step function on an Optimizer makes an update to its parameters\n",
        "          self.opt.step()\n",
        "\n",
        "      # Return the forward pass of the positive and negative samples after training\n",
        "      return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Test the Network"
      ],
      "metadata": {
        "id": "_baoVRY-hBJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "torch.manual_seed(1234)\n",
        "train_loader, test_loader = Data_loader()\n",
        "\n",
        "# Create network\n",
        "net = NetWork(Net_layers)\n",
        "x, y = next(iter(train_loader))\n",
        "x, y = x.cuda(), y.cuda()\n",
        "x_pos = y_OneHot_on_x(x, y)\n",
        "x_neg = y_OneHot_on_x(x, get_y_neg(y))\n",
        "\n",
        "\n",
        "# Train the network\n",
        "net.train(x_pos, x_neg)\n",
        "\n",
        "# Calculate and print the training accuracy\n",
        "y_pred_train = net.predict(x).cpu().numpy()\n",
        "train_accuracy = accuracy_score(y.cpu().numpy(), y_pred_train) * 100\n",
        "print(f'Train accuracy: {train_accuracy:.2f}')\n",
        "\n",
        "# Get the test data\n",
        "x_te, y_te = next(iter(test_loader))\n",
        "x_te, y_te = x_te.cuda(), y_te.cuda()\n",
        "\n",
        "# Calculate and print the test accuracy\n",
        "y_pred_test = net.predict(x_te).cpu().numpy()\n",
        "test_accuracy = accuracy_score(y_te.cpu().numpy(), y_pred_test) * 100\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "del x, y, x_pos, x_neg, net, x_te, y_te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duyx6pTSFGQi",
        "outputId": "d36c6051-e224-49a5-e3b7-6c1a5dcf180b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training layer 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [01:00<00:00, 16.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training layer 2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:40<00:00, 24.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 92.43\n",
            "Test accuracy: 92.66\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}